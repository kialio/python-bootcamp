{
 "metadata": {
  "name": "",
  "signature": "sha256:aa6245f995a6b2ebe9af6f58a1654a12adffc86913feed0653dfa98661680370"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Multiprocessing in Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font size=\"5\"> What is this multiprocessing thing?</font>\n",
      "\n",
      "<blockquote>\n",
      "<p><font size=\"5\">Process (computing)</font></p>\n",
      "\n",
      "    - From Wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "<p><font size=\"3\">In computing, a process is an instance of a computer program that is being executed. It contains the program code and its current activity. Depending on the operating system (OS), a process may be made up of multiple threads of execution that execute instructions concurrently.</font></p>\n",
      "</blockquote>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font size=\"5\"> Ok, so what's a thread? </font>\n",
      "<blockquote>\n",
      "<p><font size=\"5\">Thread (computing)</font></p>\n",
      "\n",
      "    - From Wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "<p><font size=\"3\">In computer science, a thread of execution is the smallest sequence of programmed instructions that can be managed independently by an operating system scheduler. ... Multiple threads can exist within the same process and share resources such as memory, while different processes do not share these resources. In particular, the threads of a process share the latter's instructions (its code) and its context (the values that its variables reference at any given moment).</font></p>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=\"5\"> How are they different?</font></p>\n",
      "\n",
      "<p><font size=\"3\">\n",
      "Processes are separate, independent instances; threads are time-multiplexed within a process.\n",
      "</font></p>\n",
      "\n",
      "Processes are like the different rooms in the Argument Sketch; arguments and abuse are happening simulataneously."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "Image(url=\"https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcS5oq-6Z-jRxX4k5T7KdbPkI6kIHivQgkHhsJq_tIBdqOMcD9Nz\",width=400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url=\"http://upload.wikimedia.org/wikipedia/en/8/85/Argument_Clinic.png\",width=400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Threads are like the two things happening in the argument room--both an argument and a transaction are occurring in the room, but only one at a time and they take turns."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url=\"http://i1.ytimg.com/vi/HJ3mySvxQQc/0.jpg\",width=400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Processes:\n",
      " * Separate memory space (larger memory footprint)\n",
      " * Straightforward code\n",
      " * Takes advantage of multiple CPUs/cores\n",
      " \n",
      "Threads:\n",
      " * Shared memory space (lightweight, low footprint)\n",
      " * Great for making responsive UIs\n",
      " * Runs into the GIL"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The Global Interpreter Lock (GIL)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    - From wiki.python.org\n",
      "<blockquote>\n",
      "<font size=\"3\">\n",
      "<p>In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython's memory management is not thread-safe. </p>\n",
      "\n",
      "<p>...</p>\n",
      "\n",
      "<p>The GIL is controversial because it prevents multithreaded CPython programs from taking full advantage of multiprocessor systems in certain situations. Note that potentially blocking or long-running operations, such as I/O, image processing, and NumPy number crunching, happen outside the GIL. Therefore it is only in multithreaded programs that spend a lot of time inside the GIL, interpreting CPython bytecode, that the GIL becomes a bottleneck.</p>\n",
      "</font>\n",
      "</blockquote>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font size=\"3\">\n",
      "<p>Python has standard libraries for both multiprocessing and threading.</p>\n",
      "</font>\n",
      "\n",
      "* <https://docs.python.org/2.7/library/multiprocessing.html>\n",
      "* <https://docs.python.org/2.7/library/threading.html>\n",
      "\n",
      "<p></p>\n",
      "\n",
      "<font size=\"3\">\n",
      "<p>There are also packages that make the interface easier to use</p>\n",
      "</font>\n",
      "\n",
      " * <https://wiki.python.org/moin/ParallelProcessing>\n",
      "\n",
      "<p></p>\n",
      "\n",
      "<font size=\"3\">\n",
      "<p>IPython has a built-in handler for multiprocessing, including working in clusters!</p>\n",
      "</font>\n",
      "\n",
      " * <http://ipython.org/ipython-doc/dev/parallel/>\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "And now, for something completely different."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client    # Client is the basic handler for the cluster we just started.\n",
      "import time                            # We'll use the standard library module time to compare serial to parallel\n",
      "nodes=Client()                         # Create an instance of the Client class"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nodes.ids                              # the object we created has an attribute that provides a list of the ids\n",
      "                                       # for each node in our cluster."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nodes)\n",
      "print(nodes[:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview=nodes[:]                          # Here we create a direct view that applies to all of our nodes\n",
      "\n",
      "##  Quick test to show that the nodes are working correctly  ##\n",
      "n=4\n",
      "serial_result=map(lambda x:x**2, range(n))\n",
      "parallel_result=dview.map_sync(lambda x:x**2, range(n))\n",
      "print(parallel_result,serial_result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Now for a real test! Let's do, say, a few million iterations instead!  ##\n",
      "\n",
      "n=3000000\n",
      "\n",
      "t0=time.time()\n",
      "serial_result=map(lambda x:x**2, range(n))\n",
      "t1=time.time()\n",
      "\n",
      "print(\"Done in {0}s\".format(t1-t0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t0=time.time()\n",
      "parallel_result=dview.map_sync(lambda x:x**2, range(n))\n",
      "t1=time.time()\n",
      "print(\"Done in {0}s\".format(t1-t0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  We can execute statements within each node  ##\n",
      "\n",
      "for i in range(4):\n",
      "    nodes[i].execute('start={0}*1250000'.format(i))\n",
      "    nodes[i].execute('stop={0}*1250000'.format(i+1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  Variables can be pulled from each node as well, but it's a little funny  ##\n",
      "\n",
      "nodes[0].pull('stop')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  Just like pulling variables, we can push variables to each node  ##\n",
      "\n",
      "nodes[0].push({'start':0, 'stop':10000000})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nodes[0].pull('stop').get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  IPython supports a shortcut notation that makes this easier  ##\n",
      "\n",
      "nodes[0]['stop']=1250000\n",
      "nodes[0]['stop']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  Which can also be applied to a list of direct views, but   ##\n",
      "##  pushing variables only works if we push the same value to  ##\n",
      "##  each node.                                                 ##\n",
      "\n",
      "dview['start']=123\n",
      "print(dview['start'],dview['stop'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  We're not limited on the types of objects we can push to the nodes.  ##\n",
      "\n",
      "def square(x):\n",
      "    return x**2\n",
      "\n",
      "dview['square']=square\n",
      "print(dview['square'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  If we need to import modules, it can be done synchronously across all nodes.  ##\n",
      "\n",
      "with dview.sync_imports():\n",
      "    import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  Now to use our cluster. Let's define a function we want each one to perform  ##\n",
      "##  on their respective values of start and stop.                                ##\n",
      "\n",
      "def f():\n",
      "    a=0\n",
      "    global start,stop\n",
      "    for i in range(start,stop):\n",
      "        a+=square(i)\n",
      "    return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  First a serial result; we'll use only one node to compute the sum of the first 50,000,000 squares.  \"\"\n",
      "\n",
      "nodes[0]['start']=0\n",
      "nodes[0]['stop']=50000000\n",
      "\n",
      "serial_result=nodes[0].apply(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  Since the computation is done asynchronously, we can keep working while it runs in the background.  ##\n",
      "\n",
      "for i in range(10):\n",
      "    print(\"The square of entry {0} is {1}.\".format(i,i**2))\n",
      "#serial_result.ready()\n",
      "#serial_result.elapsed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  If we need to block execution and wait for the process to finish, we can do that.  ##\n",
      "\n",
      "serial_result.wait_interactive()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  Now that the task is done, we can get the result.  ##\n",
      "\n",
      "serial_result.get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##  Now for the parallel method! Each node has its own start and stop, and will handle an equal  ##\n",
      "##  portion of the load: node 0 will do the first 1/4 values, node 1 the second 1/4, and so on.  ##\n",
      "\n",
      "for i in range(4):\n",
      "    nodes[i]['start']=i*12500000\n",
      "    nodes[i]['stop']=(i+1)*12500000\n",
      "\n",
      "print(dview['start'],dview['stop'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parallel_result=dview.apply(f)\n",
      "parallel_result.wait_interactive()\n",
      "parallel_result.get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(parallel_result.get())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}